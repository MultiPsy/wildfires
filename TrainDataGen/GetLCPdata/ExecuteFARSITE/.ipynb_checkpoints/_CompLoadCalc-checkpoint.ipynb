{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "659e3ad1-2929-49b5-b72b-5f58394122f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "make: Nothing to be done for 'all'.\n",
      "2016 ***************************************************************************************************************\n",
      "al_caney_head\n",
      "al_half_way\n",
      "al_lake_chinnabee\n",
      "al_lookout_mountain\n",
      "al_power_horn\n",
      "ar_pipeline\n",
      "ar_sweetwater\n",
      "ar_whitaker_point\n",
      "az_airstrip\n",
      "az_baca\n",
      "az_baker_canyon\n",
      "time:  0.07245111465454102\n",
      "\n",
      "az_baldwin\n",
      "az_bert\n",
      "az_black_peak\n",
      "time:  0.14886903762817383\n",
      "\n",
      "az_brown\n",
      "az_burro\n",
      "az_cedar\n",
      "az_choulic\n",
      "az_coco\n",
      "az_cowboy\n",
      "az_cumero\n",
      "time:  1.2715680599212646\n",
      "\n",
      "az_fill\n",
      "az_freeze\n",
      "az_fresnal\n",
      "az_fuller\n",
      "az_fulton\n",
      "az_jack\n",
      "az_juniper\n",
      "az_la_sierra\n",
      "time:  0.2855567932128906\n",
      "\n",
      "az_lion_fta\n",
      "az_maple\n",
      "az_mormon\n",
      "az_mule_ridge\n",
      "time:  0.4006690979003906\n",
      "\n",
      "az_paddy_creek\n",
      "az_peaks\n",
      "az_pivot_rock\n",
      "az_sam_jim\n",
      "az_skeleton\n",
      "az_sunflower\n",
      "az_tenderfoot\n",
      "az_turkey_track\n",
      "az_wildcat\n",
      "time:  411.2394199371338\n",
      "time2:  414.39127588272095\n",
      "\n",
      "ca_ash\n",
      "ca_bluecut\n",
      "time:  0.6636872291564941\n",
      "\n",
      "ca_border_3\n",
      "time:  0.021008968353271484\n",
      "\n",
      "ca_canyon\n",
      "time:  0.346071720123291\n",
      "\n",
      "ca_cedar_sqf\n",
      "ca_chimney_cnd\n",
      "ca_chimney_slu\n",
      "ca_clark\n",
      "ca_clayton\n",
      "ca_cold\n",
      "ca_coleman\n",
      "ca_crown\n",
      "ca_curry\n",
      "ca_deer\n",
      "ca_erskine\n",
      "time:  0.020691633224487305\n",
      "\n",
      "ca_evergreen\n",
      "ca_fish\n",
      "ca_gap\n",
      "time:  0.02006244659423828\n",
      "\n",
      "ca_goose\n",
      "time:  0.04649162292480469\n",
      "\n",
      "ca_havila\n",
      "ca_hidden\n",
      "ca_holy\n",
      "time:  0.03161787986755371\n",
      "\n",
      "ca_horseshoe\n",
      "ca_jacobson\n",
      "ca_lakes\n",
      "ca_lakes_ynp-0041_yose-kc3l\n",
      "ca_loma\n",
      "ca_marina\n",
      "ca_marshes\n",
      "ca_meadow\n",
      "ca_mineral\n",
      "ca_mokelumne\n",
      "ca_old\n",
      "time:  684.7550055980682\n",
      "time2:  689.104691028595\n",
      "\n",
      "ca_onyx\n",
      "time:  182.84501194953918\n",
      "time2:  184.78319001197815\n",
      "\n",
      "ca_owens_river\n",
      "time:  208.9826443195343\n",
      "time2:  210.70612692832947\n",
      "\n",
      "ca_pilot\n",
      "time:  250.86270403862\n",
      "time2:  252.90133094787598\n",
      "\n",
      "ca_pine\n",
      "time:  0.43792033195495605\n",
      "\n",
      "ca_pony\n",
      "time:  21.36376667022705\n",
      "time2:  21.714611291885376\n",
      "\n",
      "ca_reservoir\n",
      "time:  95.81597995758057\n",
      "time2:  97.07221555709839\n",
      "\n",
      "ca_rey\n",
      "time:  433.5930857658386\n",
      "time2:  436.0723867416382\n",
      "\n",
      "ca_roblar\n",
      "time:  794.548045873642\n",
      "time2:  800.160238981247\n",
      "\n",
      "ca_rock_creek\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "num_iter = 5\n",
    "wildfire = '/home/qweddww123/farsite/TrainDataGen/WildfireShapefiles'\n",
    "os.chdir(\"/home/qweddww123/farsite/src/\")\n",
    "os.system(\"make\")\n",
    "\n",
    "for year in sorted(os.listdir(wildfire), key=int):\n",
    "    print(year, '***************************************************************************************************************')\n",
    "    for target_fire in sorted(os.listdir(wildfire+'/'+year), key=str):\n",
    "        path = wildfire+'/'+year\n",
    "        \n",
    "        if(target_fire[0] == '.'):\n",
    "            continue\n",
    "        elif(target_fire.split('_')[0] == 'ak' or target_fire.split('_')[0] == 'AK'):\n",
    "            continue\n",
    "        elif(target_fire.split('_')[0] == 'hi'):\n",
    "            continue\n",
    "        #elif(target_fire.split('_')[0] == 'ca'):\n",
    "        #    continue\n",
    "        else:\n",
    "        #if (target_fire.split('_')[0] == 'ca'):\n",
    "            print(target_fire)\n",
    "            shpdir = wildfire+'/'+year+'/'+target_fire\n",
    "            wildfire_time = sorted(os.listdir(shpdir), key=str)[0]\n",
    "            for txt in sorted(os.listdir(shpdir+'/'+wildfire_time), key=str):\n",
    "                if not os.path.isfile(shpdir+'/'+wildfire_time+'/'+\"MLinput/Number_of_points.csv\"):\n",
    "                    #if txt == 'inputtxt.txt' and os.path.isfile(shpdir+'/'+wildfire_time+'/'+'output.csv')==False:\n",
    "                    if txt == 'inputtxt.txt':\n",
    "                        cmd1 = \"./TestFARSITE \"+shpdir+'/'+wildfire_time+'/'+txt\n",
    "                        start = time.time()\n",
    "                        start2 = time.time()\n",
    "                        for i in range(1, num_iter+1):\n",
    "                            cmd2 = \" > \" + shpdir+'/'+wildfire_time+'/'+\"log\" + str(i) + \".csv\"\n",
    "                            #save the results into log files\n",
    "                            os.system(cmd1 + cmd2)\n",
    "                        CompLoadArr = [[0 for i in range(600)] for i in range(600)]\n",
    "                        list = []\n",
    "\n",
    "                        #read csv files and put the values in array\n",
    "                        for i in range(1, num_iter+1):\n",
    "                            list.append([])\n",
    "                            with open(shpdir+'/'+wildfire_time+'/'+\"log\" + str(i) + \".csv\", 'r') as file_name:\n",
    "                                csv_data = csv.reader(file_name)\n",
    "                                for line in csv_data:\n",
    "                                    list[i-1].append(line)\n",
    "\n",
    "                        print(\"time: \", time.time() - start)\n",
    "\n",
    "                        for i in range(1, num_iter+1):\n",
    "                            # read csv file with pandas\n",
    "                            try:\n",
    "                                df = pd.read_csv(shpdir+'/'+wildfire_time+'/'+\"log\" + str(i) + \".csv\")\n",
    "                            except:\n",
    "                                break\n",
    "\n",
    "                            # count the row and col\n",
    "                            row_cnt = len(df.axes[0]) + 1\n",
    "\n",
    "                            # sum the times\n",
    "                            for j in range(row_cnt):\n",
    "                                try:\n",
    "                                    CompLoadArr[int(list[i-1][j][0])][int(list[i-1][j][1])] += float(list[i-1][j][2])\n",
    "                                except:\n",
    "                                    continue\n",
    "\n",
    "                        num_points_arr = [[ 0 for i in range(600) ] for i in range(600) ]\n",
    "                        df = pd.read_csv(shpdir+'/'+wildfire_time+'/'+\"log\" + str(1) + \".csv\")\n",
    "                        row_cnt = len(df.axes[0]) + 1\n",
    "                        #count the number of duplicate disaster spread computing points throughout a csv file\n",
    "                        try:\n",
    "                            for i in range(row_cnt):\n",
    "                                num_points_arr[int(list[0][i][0])][int(list[0][i][1])] += 1\n",
    "                        except:\n",
    "                            print()\n",
    "                            continue\n",
    "\n",
    "                        arr = np.array(num_points_arr)\n",
    "                        df = pd.DataFrame(arr)\n",
    "                        df.to_csv(shpdir+'/'+wildfire_time+'/'+'Number_of_points.csv', header=False, index=False)\n",
    "\n",
    "                        '''\n",
    "                        for i in range(600):\n",
    "                            for j in range(600):\n",
    "                                if CompLoadArr[i][j] != 0:\n",
    "                                    #calculate the mean computing load of each cell\n",
    "                                    continue\n",
    "                                    #print(\"[\" + str(i) + \", \" + str(j) + \", \" + str(round(((CompLoadArr[i][j])/num_iter),4)) + \"]\")\n",
    "                        '''\n",
    "\n",
    "                        #write the computing load on each cell\n",
    "                        #*********************************************************************************************************#\n",
    "                        #labelling the computing loads in every time step to 600*600 matrix as machine learning output data(label)\n",
    "                        #*********************************************************************************************************#                    \n",
    "                        arr = np.array(CompLoadArr)\n",
    "                        df = pd.DataFrame(arr)\n",
    "                        df.to_csv(shpdir+'/'+wildfire_time+'/'+'output.csv', index=False)\n",
    "\n",
    "                        print(\"time2: \", time.time() - start2)\n",
    "                        print()\n",
    "\n",
    "print(\"Output.csv generation completed!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "746fdf59-e5f4-428b-b51c-fe8cce3081b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
